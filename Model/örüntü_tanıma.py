# -*- coding: utf-8 -*-
"""örüntü-tanıma.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1liUJF2LiQC5T1ata9yKXsuGL9RNAG6-N
"""

# Gerekli Kütüphaneler
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

# Veri Setinin Yüklenmesi
veri_yolu = "/content/drive/MyDrive/Örüntü-Tanıma-Veri-Seti/emotions.csv"
veri_seti = pd.read_csv(veri_yolu)

# Verinin Hazırlanması
def veri_hazirla(veri_seti):
    kodlama = {'NEUTRAL': 0, 'POSITIVE': 1, 'NEGATIVE': 2} 
    kodlanmis_veri = veri_seti.replace(kodlama)

    X = kodlanmis_veri.drop(["label"], axis=1)
    y = tf.keras.utils.to_categorical(kodlanmis_veri['label'].values)

    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    return X, y

pozitif_veri = veri_seti[veri_seti["label"]=="POSITIVE"]
negatif_veri = veri_seti[veri_seti["label"]=="NEGATIVE"]
notr_veri = veri_seti[veri_seti["label"]=="NEUTRAL"]

# Pozitif, Negatif ve Nötr örneklere erişim
pozitif_ornek = pozitif_veri.iloc[0,:-1]
negatif_ornek = negatif_veri.iloc[0,:-1]
notr_ornek = notr_veri.iloc[0,:-1]

# Sinyallerin StandardScaler ile ölçeklendirilmesi
scaler = StandardScaler()

pozitif_ornek_scaled = scaler.fit_transform(pozitif_ornek.values.reshape(-1, 1))
negatif_ornek_scaled = scaler.fit_transform(negatif_ornek.values.reshape(-1, 1))
notr_ornek_scaled = scaler.fit_transform(notr_ornek.values.reshape(-1, 1))

# Her bir sinyalin çizilmesi
plt.figure(figsize=(20,6))

plt.subplot(3,1,1)
plt.plot(pozitif_ornek_scaled)
plt.title('Pozitif Sinyal')

plt.subplot(3,1,2)
plt.plot(negatif_ornek_scaled, 'orange')
plt.title('Negatif Sinyal')

plt.subplot(3,1,3)
plt.plot(notr_ornek_scaled, 'green')
plt.title('Nötr Sinyal')

plt.tight_layout()
plt.show()

# Verinin Hazırlanması ve Eğitim/Test Kümelerine Ayırma
X, y = veri_hazirla(veri_seti)
X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.2, random_state=4)

# Modelin Hazırlanması
def model_olustur():
    model = tf.keras.Sequential()   
    model.add(tf.keras.layers.Reshape((X_egitim.shape[1], 1), input_shape=(X_egitim.shape[1],)))   
    # İlk GRU katmanı. 1024 nöron ile katman eklendi.
    model.add(tf.keras.layers.GRU(1024, return_sequences=True))   
    # Dropout katmanı. Overfitting'i önlemek için kullanılır.
    model.add(tf.keras.layers.Dropout(0.2))   
    # İkinci GRU katmanı.
    model.add(tf.keras.layers.GRU(2048, return_sequences=True))   
    # Tekrar Dropout katmanı.
    model.add(tf.keras.layers.Dropout(0.3))
    # Üçüncü GRU katmanı
    model.add(tf.keras.layers.GRU(64))
    model.add(tf.keras.layers.Flatten())   
    # Tam bağlantılı katman (Dense layer)
    model.add(tf.keras.layers.Dense(32, activation='relu'))    
    # Son katman. Sınıflandırma işlemi burada gerçekleşir.
    model.add(tf.keras.layers.Dense(3, activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    return model

# Modelin Eğitilmesi
model = model_olustur()
gecmis = model.fit(X_egitim, y_egitim, epochs=15, validation_split=0.1)

# Modelin Değerlendirilmesi
kayip, dogruluk = model.evaluate(X_test, y_test)
print(f"Test veri setindeki kayıp: {kayip*100}",f"\nEğitim veri setindeki doğruluk: {dogruluk*100}")

# Kayıp ve Doğruluk Değerlerinin Grafiği
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(gecmis.history['loss'], label='Eğitim Kaybı')
plt.plot(gecmis.history['val_loss'], label='Doğrulama Kaybı')
plt.title('Kayıp Değerleri')
plt.xlabel('Epoch')
plt.ylabel('Kayıp')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(gecmis.history['accuracy'], label='Eğitim Doğruluk')
plt.plot(gecmis.history['val_accuracy'], label='Doğrulama Doğruluk')
plt.title('Doğruluk Değerleri')
plt.xlabel('Epoch')
plt.ylabel('Doğruluk')
plt.legend()

plt.tight_layout()
plt.show()

# Modelin Değerlendirilmesi ve Doğruluk Matrisi
kayip, dogruluk = model.evaluate(X_test, y_test)
tahminler = model.predict(X_test)
tahmin_etiketleri = np.argmax(tahminler, axis=1)
gercek_etiketler = np.argmax(y_test, axis=1)

print(classification_report(gercek_etiketler, tahmin_etiketleri))